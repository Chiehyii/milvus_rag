# ------------------------------- 載入環境變數 -------------------------------
import os
import json

# ------------------------------- 準備資料 -------------------------------
from langchain_text_splitters import RecursiveCharacterTextSplitter
from glob import glob
from openai import OpenAI
# from pymilvus import model
from tqdm import tqdm
from dotenv import load_dotenv

load_dotenv()
zilliz_api_key = os.getenv("ZILLIZ_API_KEY")
openai_api_key = os.getenv("OPENAI_API_KEY")
# gemini_api_key = os.getenv("GEMINI_API_KEY")
openai_client = OpenAI(api_key=openai_api_key)
# gemini_ef = model.dense.GeminiEmbeddingFunction(
#     model_name='gemini-embedding-001', # 指定您要的模型
#     api_key=gemini_api_key,
# )
def emb_text(text):
    return (
        openai_client.embeddings.create(input=text, model="text-embedding-3-small")
        .data[0]
        .embedding
        # gemini_ef.encode_documents([text])[0]
    )

with open("config.json", "r", encoding="utf-8") as f:
    config = json.load(f)

data = []
doc_id = 0

for file_path in glob("milvus_docs/**/*.md", recursive=True):
    with open(file_path, "r", encoding="utf-8") as file:
        file_text = file.read()
    # text_lines = file_text.split("# ")
    # text_lines = [line.strip() for line in text_lines if line.strip()] # 過濾空白內容
    

    meta = config.get(os.path.basename(file_path), {})

    # 使用 RecursiveCharacterTextSplitter 進行切割
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    chunks = text_splitter.split_text(file_text)
    text_lines = [chunk.strip() for chunk in chunks if chunk.strip()] # 過濾空白內容

    url = meta.get("source_url", "")
    statuses = meta.get("status", [])
    edu_systems = meta.get("edu_system", [])
    subsidy_types = meta.get("subsidy_type", [])

    # 為每個文字段落加入來源資訊
    for line in tqdm(text_lines, desc=f"Processing(Creating embeddings) {os.path.basename(file_path)}"):
        data.append({
            "id": doc_id,
            "text": line,
            "source_file": os.path.basename(file_path), # 檔案名稱
            "source_path": file_path, # 完整路徑
            "source_url":url,
            "status": statuses,
            "edu_system": edu_systems,
            "subsidy_type":subsidy_types,
            "vector": emb_text(line) # 向量嵌入
        })
        doc_id += 1

print(f"總共讀取到 {len(data)} 筆文本資料")

# ------------------------------- 嵌入模型 -------------------------------


test_embedding = emb_text("Hello, world!")
embedding_dim = len(test_embedding)
print(f"Embedding維度: {embedding_dim}, 前10個值: {test_embedding[:10]} ...")

# ------------------------------- 將資料載入Milvus向量資料庫 -------------------------------

# ========建立資料========
from pymilvus import MilvusClient, DataType, connections, CollectionSchema, FieldSchema, Collection

CLUSTER_ENDPOINT="https://in03-a6f08ce2ff778ed.serverless.gcp-us-west1.cloud.zilliz.com:443"
milvus_client = MilvusClient(
                    uri=CLUSTER_ENDPOINT,
                    token=zilliz_api_key,
                    )

# 建立 schema
schema = milvus_client.create_schema(
    auto_id=False,
    enable_dynamic_field=True
)

collection_name = "rag5_scholarships_hybrid"

schema.add_field("id", DataType.INT64, is_primary=True)
schema.add_field("text", DataType.VARCHAR, max_length=10000)
schema.add_field("source_file", DataType.VARCHAR, max_length=256)
schema.add_field("source_path", DataType.VARCHAR, max_length=2048)
schema.add_field("source_url", DataType.VARCHAR, max_length=200)
schema.add_field("status", DataType.ARRAY, element_type=DataType.VARCHAR, max_capacity=200, max_length=200, nullable=True)
schema.add_field("edu_system", DataType.ARRAY, element_type=DataType.VARCHAR, max_capacity=200, max_length=200, nullable=True)
schema.add_field("subsidy_type", DataType.ARRAY, element_type=DataType.VARCHAR, max_capacity=200, max_length=200, nullable=True)
schema.add_field("vector", DataType.FLOAT_VECTOR, dim=1536)

# 若 collection 已存在則刪除
if milvus_client.has_collection(collection_name):
    milvus_client.drop_collection(collection_name)

# 創建 collection
milvus_client.create_collection(
    collection_name=collection_name,
    schema=schema,
    consistency_level="Bounded"
)

# ========插入資料========
insert_result = milvus_client.insert(collection_name=collection_name, data=data)
print(f"插入結果: {insert_result}")

# ------------------------------- 修正後的流程 -------------------------------

# 1. 為 vector 欄位建立索引 (必須在 load 之前)
print("正在為 vector 欄位建立索引...")
index_params = milvus_client.prepare_index_params()

# 為名為 "vector" 的欄位新增索引
index_params.add_index(
    field_name="vector",
    index_type="AUTOINDEX",  # 讓 Milvus 自動選擇最佳索引類型
    metric_type="COSINE"      # 設定向量距離的計算方式，L2 (歐氏距離) 是最常用的
)

milvus_client.create_index(
    collection_name=collection_name,
    index_params=index_params
    
)
print("索引建立完成。")

# 2. 載入集合至記憶體 (現在可以成功了)
print("正在將集合加載到記憶體...")
milvus_client.load_collection(collection_name=collection_name)
print("集合已成功載入到記憶體。")

# 3. 驗證資料是否已存在且可查詢
stats = milvus_client.get_collection_stats(collection_name=collection_name)
print(f"\n集合 '{collection_name}' 的統計資訊: {stats}")

# 執行一個簡單的查詢來確認資料可讀取
query_res = milvus_client.query(
    collection_name=collection_name,
    filter='array_contains(status, "原住民") and array_contains(edu_system, "大學部")',
    output_fields=["id", "source_file"]
)
print(f"\n執行查詢驗證，成功取回 {len(query_res)} 筆資料:")
print(query_res)




# ------------------------------- 建立 RAG -------------------------------
# question = "原住民學生可以申請哪種獎助學金？"

# search_res = milvus_client.search(
#     collection_name=collection_name,
#     data=[emb_text(question)], # 對問題進行嵌入
#     limit=10,  # 想要找回幾筆資料
#     search_params={"metric_type": "IP", "params": {}}, # inner product distance
#     output_fields=["text", "source_file", "source_path"], # 回傳的欄位
# )
# print(f"搜尋結果數量: {len(search_res[0]) if search_res else 0}")
# # 檔案名稱到網址的對應表
# file_to_url = {
#     "慈濟大學高教深耕學.md": "https://yizhu.tcu.edu.tw/?p=3132",
#     "新北市高級中等以上學校原住民學生獎學金.md": "https://yizhu.tcu.edu.tw/?p=3313",
#     "校內工讀助學.md": "https://yizhu.tcu.edu.tw/?p=3182"
# }

# print("\n=== Milvus檢索結果 ===")
# for i, res in enumerate(search_res[0], 1):
#     text = res["entity"]["text"]
#     source_file = res["entity"]["source_file"]
#     url = file_to_url.get(source_file, "無網址資訊")
#     distance = res["distance"]

#     print(f"結果 {i} (相似度: {distance:.4f}):")
#     print(f"內容: {text[:200]}...")  # 只顯示前200字
#     print(f"來源檔案: [{source_file}]({url})")
#     print("-" * 50)

# # 建立包含來源的上下文
# context_with_sources = []
# for i, res in enumerate(search_res[0], 1):
#     text = res["entity"]["text"]
#     source_file = res["entity"]["source_file"]
#     url = file_to_url.get(source_file, "無網址資訊")

#     if url != "無網址資訊":
#         context_with_sources.append(f"【參考資料 {i}】\n{text}\n[來源: {url}]\n")
#     else:
#         context_with_sources.append(f"【參考資料 {i}】\n{text}\n[來源: {source_file}]\n")

# context = "\n\n".join(context_with_sources)

# # ==============用 LLM 來回答問題=============

# SYSTEM_PROMPT = """
# 你是一個智慧型 AI 助手。你的任務是根據提供的上下文資訊，找出並回答相關問題。
# 重要：在回答中引用資訊時，請使用 [來源: 網址] 的格式標註每個引用的來源。
# 如果有提供網址，請優先使用網址作為來源標註。
# """

# USER_PROMPT = f"""
# 請仔細閱讀以下以 <context> 標籤括住的內容，並依據其中的資訊，回答 <question> 標籤中的問題。
# 請根據以下上下文資訊回答問題，並在每個引用的資訊後面標註來源。

# <context>
# {context}
# </context>

# <question>
# {question}
# </question>

# 請在回答中包含適當的來源標註。
# """

# response = openai_client.chat.completions.create(
#     model="gpt-4o-mini",
#     messages=[
#         {"role": "system", "content": SYSTEM_PROMPT},
#         {"role": "user", "content": USER_PROMPT},
#     ],
# )
# print(response.choices[0].message.content)